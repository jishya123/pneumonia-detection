{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "p0BH7ARBa0AZ",
        "outputId": "6f8854a7-bf1e-446a-d3bb-f75150789c88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\hp\\\\Desktop\\\\dsp_project\\\\chest_xray\\\\train'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f0ffb3d47047>\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mtraining_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr\"C:\\Users\\hp\\Desktop\\dsp_project\\chest_xray\\train\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mtraining_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrescale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mdata_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow_from_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1647\u001b[0m             \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0my\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m         \"\"\"\n\u001b[0;32m-> 1649\u001b[0;31m         return DirectoryIterator(\n\u001b[0m\u001b[1;32m   1650\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\hp\\\\Desktop\\\\dsp_project\\\\chest_xray\\\\train'"
          ]
        }
      ],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in\n",
        "from google.colab import drive\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "#import os\n",
        "#for dirname, _, filenames in os.walk(r'C:\\Users\\91939\\Desktop\\python_ws'):\n",
        "#    for filename in filenames:\n",
        "#       print(os.path.join(dirname, filename))\"\"\"\n",
        "\n",
        "# Any results you write to the current directory are saved as output.\n",
        "\n",
        "\n",
        "# In[5]:\n",
        "\n",
        "\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# In[6]:\n",
        "\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "# In[7]:\n",
        "\n",
        "\n",
        "training_dir = r\"C:\\Users\\hp\\Desktop\\dsp_project\\chest_xray\\train\"\n",
        "training_generator = ImageDataGenerator(rescale = 1/255)\n",
        "data_train = training_generator.flow_from_directory(training_dir,target_size = (120,120), batch_size=8,class_mode = \"binary\")\n",
        "\n",
        "\n",
        "# In[8]:\n",
        "\n",
        "\n",
        "valid_dir = r\"C:\\Users\\hp\\Desktop\\dsp_project\\chest_xray\\val\"\n",
        "validation_generator = ImageDataGenerator(rescale = 1/255)\n",
        "data_valid = validation_generator.flow_from_directory(valid_dir,target_size = (120,120), batch_size=8,class_mode = \"binary\")\n",
        "\n",
        "\n",
        "# In[9]:\n",
        "\n",
        "\n",
        "test_dir = r\"C:\\Users\\hp\\Desktop\\dsp_project\\chest_xray\\test\"\n",
        "testing_generator = ImageDataGenerator(rescale = 1/255)\n",
        "data_test = testing_generator.flow_from_directory(test_dir,target_size = (120,120), batch_size=8,class_mode = \"binary\")\n",
        "\n",
        "\n",
        "# In[10]:\n",
        "\n",
        "\n",
        "#CNN model\n",
        "#color data 3 in next at input size 1 for black and white\n",
        "model = tf.keras.Sequential([tf.keras.layers.Conv2D(32, (3,3), input_shape = (120,120,3), activation = \"relu\"),\n",
        "                            tf.keras.layers.MaxPooling2D(2,2),\n",
        "                            tf.keras.layers.Conv2D(64, (3,3), activation = \"relu\"),\n",
        "                            tf.keras.layers.MaxPooling2D(2,2),\n",
        "                            tf.keras.layers.Conv2D(128,(3,3), activation = \"relu\"),\n",
        "                            tf.keras.layers.MaxPooling2D(2,2),\n",
        "                            tf.keras.layers.Conv2D(256,(3,3), activation = \"relu\"),\n",
        "                            tf.keras.layers.MaxPooling2D(2,2),\n",
        "                            tf.keras.layers.Conv2D(512,(3,3), activation = \"relu\"),\n",
        "                            tf.keras.layers.MaxPooling2D(2,2),\n",
        "                            tf.keras.layers.Flatten(),\n",
        "                            tf.keras.layers.Dense(256,activation ='relu'),\n",
        "                            tf.keras.layers.Dense(1,activation ='sigmoid')])\n",
        "\n",
        "\n",
        "# In[11]:\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# In[12]:\n",
        "\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 0.001),loss = \"binary_crossentropy\", metrics = [\"acc\"])\n",
        "\n",
        "\n",
        "# In[13]:\n",
        "\n",
        "\n",
        "history = model.fit(data_train, epochs=2, validation_data=data_valid)\n",
        "\n",
        "\n",
        "# In[14]:\n",
        "\n",
        "\n",
        "model.evaluate(data_test)\n",
        "\n",
        "\n",
        "# In[15]:\n",
        "\n",
        "\n",
        "predictions = model.predict(data_test)\n",
        "\n",
        "\n",
        "# In[16]:\n",
        "\n",
        "\n",
        "predictions\n",
        "\n",
        "model.save('/content/drive/My Drive/my_model.h5')\n",
        "print(\"Model saved to Google Drive\")"
      ]
    }
  ]
}